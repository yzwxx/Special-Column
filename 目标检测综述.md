### 4.2.2 目标检测 Object detection

目标检测是图像分类的延伸，除了分类任务，还需要给定多个检测目标的坐标位置。如图所示，基于CNN的检测器需要完成定位和分类两个任务。

<div align="center">
	<img src="images/od.jpg" width="70%" height="70%"/>'
	<br>  
	<em align="center">目标检测实例</em>  
</div>



目前基于CNN的主流目标检测框架包括YOLO[8]、SSD[9]、Faster R-CNN[11]和Mask R-CNN[13]等，均在各大目标检测数据集取得了相当惊人的成绩。其中，最新的YOLO9000框架速度非常惊人并且在VOC 2007的数据上表现超过SSD和Faster R-CNN，而Mask R-CNN是在Faster R-CNN基础上进行改进，都是基于CNN提出待选框，把待选框经过一系列处理后实现检测和分割的并行处理，大大提升了准确率和性能。

目标检测发展历史大致如下，R.Girshick于2014年发表的R-CNN是最早基于CNN的目标检测方法，然后基于这条路线依次演进出SPP net, Fast R-CNN, Faster R-CNN，然后到2017年出现的Mask R-CNN。

顾名思义，R-CNN即区域卷积神经网络。其提出为目标检测领域提供了两个新思路：首先提出了将候选子图片输入CNN模型用于目标检测和分割的方法，其次提出了对于数据集标签数据有限情况下的训练方法。作者证明，使用在其他有标签数据集训练好的模型，然后再用当前少量标签数据进行特定任务的微调训练，最终可以得到明显的效果提升。目标检测与目标识别不同之处在于需要对被检测目标进行定位。当时常用的定位方法有回归，滑动窗等。不同的地方是，R-CNN非常简单粗暴，使用Selective Search算法在图片中选出2000张可能存在目标的候选子图片(把选区子图片作为候选物体位置的步骤称为Region Proposal），从而解决了定位问题。然后，把每一个子图片大小调整为一个固定大小，逐一输入到一个预先训练好的CNN用于特征提取，最后再将提取到的特征输入到SVM分类器（丢掉CNN中的softmax分类器采用SVM分类器可以得到一定的提升），这样就可以通过计算推断每个候选区域的物体属于什么类别，概率是多少。最后把物体概率小的区域去掉，就得到图中物体的位置和类别。

不过R-CNN有三个明显的缺点。第一，它把每一个子图片都调整到一个固定大小，这样的话原图长宽比例会扭曲，影响后面CNN分类器的效果。第二，它需要把每一个候选子图片逐一输入到CNN里做分类，相当于做了2000次特征提取和分类计算，速度非常慢，如果候选子图之间有重复的部分，CNN的计算也将重复多次，这就浪费了计算资源，没有实用意义。第三，其训练是多个阶段的，对于目标检测而言，R-CNN首先需要对预训练模型进行特定类别物体的微调训练，然后再训练SVM对提取到的特征进行分类，最后还需训练候选框回归器(Bounding-box Regressor)对候选子图中的目标进行精确地提取。以上三个阶段是互相分离的，要一步一步进行。

为了解决第一个、第二个缺点（也是最为严重的问题），何凯明提出了SPP net（Spatial Pyramid Pooling）[20]。其思路是先对任意大小输入图片整体进行卷积操作，然后对得到的特征图对应候选子图位置做空间金字塔池化（Spatial Pyramid Pooling），该操作采用了多种不同的池化尺度，将多个池化后的特征串联起来作为定长的特征向量。因此，通过空间金字塔池化操作，对于任意尺寸的候选区域，经过SPP后都会得到固定长度的特征向量，然后再把该特征图继续输入到后续的CNN分类器中。总体来说，SPP net通过对原始输入图片进行卷积后再获取各个候选子图对应特征而非对各个候选子图分别输入CNN处理，进而大大减少了计算特征，加快了目标检测速度。同时，采用空间金字塔池化的网络不需要固定尺寸的输入图像，从而也弥补了第一个缺陷。然而第三个不足之处仍然存在。

为了进一步提升速度和解决第三个问题，后续R.Girshick提出了端到端训练的Fast R-CNN网络。类似于SPP net，Fast R-CNN网络用ROI(Region Of Interest)池化，该操作可以视为空间金字塔池化的简化版本，即只使用了一种池化尺度。当然，多尺度的池化可以获得性能上的微小提升，但是是以牺牲速度为代价的。Fast R-CNN在训练时通过共享计算使效率更高，比如，每个mini-batch的训练样本来自N=2张输入图片，为了获取R=128个学习样本，需要从每张图片中采样R/N=128/2=64个ROI。由于对于同一张图片的不同ROI之间在前向传播和反向传播时是共享计算、共享内存的，因此相比128个来自128张图片的ROI（也就是在R-CNN和SPP net所采用的），Fast R-CNN大致有64倍的提速。此外，该网络将候选框回归任务部分也一同通过CNN实现，在卷积层后面的全连接层分为两支，一支用于识别目标类别，另一支用于预测回归框所在位置及长宽。值得注意的是，为了实现端到端训练，Fast R-CNN放弃了SVM分类器而是选择微调后网络自身的softmax分类器。这样一来，特征提取、目标分类、候选框回归三部分可以同时进行端到端（end-to-end）训练。

即便如此，Fast R-CNN仍然还不够快，其瓶颈在于使用了Selective Search算法[21]来生成候选子图（只通过CPU计算而没有GPU加速）。为了进一步提升性能，R.Girshick继续提出了Faster R-CNN，使用Region Proposal Networks（RPN），即通过神经网络来学习如何生成Region Proposal。其优势在于获得更快收敛速度的同时，将RPN与CNN部分联合训练可以提高整体效果。输入图片在经过卷积层提取特征图后，RPN在特征图上通过滑动窗的方式，在每个位置生成一定数量的anchors（包括不同的尺度和长宽比，这里选取k个）,每个anchor都是该特征图当前位置所对应输入图片的一个区域。对于每个anchor位置RPN采用$3\times3$大小的滑动窗，从该区域提取特征并压缩得到256维度的特征向量，然后通过一支全连接二分类网络来计算k个anchor所对应候选区域是否含有目标的概率，通过另一支全连接网络来预测k个尺度的候选框的位置以及长宽。通过缩小各个anchor对应的k个候选框与ground-truth直接的损失函数，RPN可以学习如何从特征图中检测到更有可能包含目标的候选子图。在训练阶段，RPN与CNN交替训练，并且共享特征提取部分的网络参数，从而可以端到端训练。相比Selective Search算法，RPN尽管产生的候选子图个数减少但是其召回率下降并不大，同时由于GPU加速得到显著效率提升。

以上方法的思路都很类似，即通过生成候选子图提供需要检测的位置信息，通过CNN分类得到类别信息。该方法结果精度很高然而速度始终不够快，难以满足实时性需求。YOLO（You Only Look Once）提供了一个新的思路：直接用CNN结构的输出层回归候选框位置以及长宽和目标的类别预测。这一想法将目标检测问题完全看作回归问题，简单直接而有效。YOLO将输入图片分为$7\times7$的网格，如果目标中心落在某个网格内部，那么就认为该网格负责对目标的检测和识别。将输入图片防缩到特定尺寸输入CNN，CNN中的卷积层部分负责特征提取，全连接层部分负责分类识别以及候选框回归。对于每个网格，我们可以计算其包含目标的概率，目标属于各类别概率以及候选框信息等，对于49个网格的结果采用非极大值抑制后得到剩余的候选框，就是最终的结果。这个方法最大的特点就是运行迅速，泛化能力强。不过它的缺点是很难检测到小的物体。针对这个弊端，后来又提出了YOLO2的方法，此处不再赘述。

目前很多嵌入式产品中，考虑到实时性问题，往往使用的是YOLO的技术思路。
